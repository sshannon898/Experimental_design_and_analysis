---
title: "variancestuff"
author: "Stephen Shannon"
date: "January 26, 2021"
output:
  word_document: default
  html_document: default
---

## Part I
```{r echo=FALSE}
library(ggplot2)
set.seed(1003836441)
treatment_s <- round(rexp(9, 1/3), digits=3)
treatment_t <- round(rexp(9, 1), digits = 3)

pairs <- data.frame(treatment_s, treatment_t)
print(pairs)
ggplot(pairs, aes(x=1:9), xlab="pair", ylab="Time") +
  geom_point(aes(y=treatment_s, color = "treatment_s")) +
  geom_point(aes(y=treatment_t, color="treatment_t")) +
  ggtitle("Treatment S paired with Treatment T") +
  xlab("Pair number") +
  ylab("Years before burning")
```
(1-1)

##Part II

# Completely Randomized Experiment Design

```{r echo=FALSE}
round((mean(treatment_s)-mean(treatment_t)), digits=3)
```
(2-1)

We calculate the difference in the two means to be 2.158

We wish to know if the tempature has an affect on the time until a lightbulb burns out. We will thus setup the following hypothesis test: 

H0: Tempature does not affect bulb burnout time. (Average of treatment S - Average of treatment T = 0)
HA: Tempature does affect bulb burnout time. (Average of treatment S - Average of treatment T ??? 0)

Thus, we will randomly assign each observation to a pair corresponding with another randomly chosen observation, then calculate the difference between the two means again. We will do this for every possible pair combination, this is the randomization distribution. Finally, we will determine the probability of observing a pair difference in means more extreme than our observed difference. 

For this instance, because we are interested in measuring the probability of observing a value more extreme than our current observed value, we will utilize a two sided test, as the absolute value of a negative difference can potentially be greater than our observed value, and thus would be considered a value more extreme than our observed value. 
```{r echo=FALSE}
bulbs <- c(treatment_s, treatment_t)
N <- choose(18, 9)
res <- numeric(N)
index <- combn(1:18, 9)
for (i in 1:N)
{res[i] <- mean(bulbs[index[,i]])-mean(bulbs[-index[,i]])}

hist(res, xlab="difference between pair averages",
     main="Randomization Distribution of Difference in Means")
observed <- mean(treatment_s)-mean(treatment_t)
abline(v=observed, col="red")
abline(v=-observed, col="red")


pval <- round((sum(abs(res)>=observed)/N), digits = 2)
print(pval)

```
(2-2)

The P-value is 0.32 for our two-sided randomization test, which indicates that we do not have evidence to reject the Null hypothesis, H0. That is, the probability of observing a value as extreme or more extreme than our observed value is 0.32 which does not meet the signifigance threshold of 0.05

NOTE: The distribution of the difference of the two means is bimodal, which is unexpected given that the linear combination of two gaussian variables (sample means) should also be a gaussian variable. However, if we look at the data, we have one extreme value generated from our exponetial distribution, where x=17.3, which is incredibly unlikely to arise from our particular exponential distributions. Additionally, since the mean is not a robust statistic, the group which recieves the extreme value will have a different mean than the other group, thus, the differences between the means will most frequently be at 1, -1 or 2, -2 as we see in our graphs bimodal peaks at -2 and 2. This attribute of our data will also affect the randomized paired comparison distribution of differences in means as well.

# Randomized Paired Comparison

We begin by randomly assigning each bulb to a corresponding pair that recieved the opposite pair. We observe the difference between the bulbs in the pair and repeat for all the pairs in our data. We realize that if we have 2 bulbs in a pair with 9 total pairs, then we have 2^(9) possible possible pair arrangements. We compare our observed mean difference to that of all the possible mean differences from our random pair arrangement. We construct the following hypothesis test

H0: Tempature does not affect bulb burnout time. (Mean difference between pairs = 0)
HA: Tempature does affect bulb burnout time. (Mean difference between pairs ??? 0)

As we want to measure all values that are more extreme than our observed values, we measure the absolute value of all observable mean differences in order to capture negative differences which may be more extreme than our observed mean difference.

```{r echo=FALSE}
diff <- pairs$treatment_s-pairs$treatment_t
meandiff <- mean(diff) ; meandiff

N <- 2^(9)
res <- numeric(N)
LR <- list(c(-1,1))
treatment_assignment <-expand.grid(rep(LR, 9))

for (i in 1:N)
  res[i] <-mean(as.numeric(treatment_assignment[i,])*diff)

hist(res, xlab="Mean Difference", main="Randomized Pairs Distribution")
abline(v=meandiff, col="red")
abline(v=-meandiff, col="red")

pval <- round(sum(abs(res)>=meandiff)/N,digits=2) ; pval
```
(2-3)

Our P-value for the two-sided test is 0.31, which is in close agreement to our P-value for the completely randomized experiment. We do not have sufficient evidence to reject the null hypothesis in favor of the alternative test. That is, our observed mean difference is not unlikely to be observed if it were true that the mean difference is actually 0.


##Part III

# Randomized design T-test
We will now run a Two-sample t-test of our completely randomized design of the same hypotheses as earlier:

H0: Tempature does not affect bulb burnout time. (Average of treatment S - Average of treatment T = 0)
HA: Tempature does affect bulb burnout time. (Average of treatment S - Average of treatment T ??? 0)
```{r echo=FALSE}
t.test(treatment_s,treatment_t,var.equal=FALSE)
```
(3-1)

The P-value for our two sample t-test is 0.28, which indicates that we fail to reject the null hypothesis, H0. That is, the difference of means that we observed between our treatment groups is not an extreme value if the true difference in means is 0.

# Randomized Paired design

We will now conduct a two-sample t-test of our randomized paired design.

H0: Tempature does not affect bulb burnout time. (Mean difference between pairs = 0)
HA: Tempature does affect bulb burnout time. (Mean difference between pairs ??? 0)

```{r echo=FALSE}
t.test(pairs$treatment_s,pairs$treatment_t,paired=T)
```
(3-2)

The P-value for our two sample paired t-test is 0.28, which indicates that we fail to reject the null hypothesis, H0.

# Completely Randomized Design normality check

We now check normality assumptions on our two treatment groups utilized in the completely randomized
```{r echo=FALSE}
qqnorm(treatment_s, main="Treatment S");qqline(treatment_s)
qqnorm(treatment_t,main="Treatment T");qqline(treatment_t)

```
(3-3)

Thus we see from the graphs that in addition to extreme values at the tails, the points seem to conform to a curve with positive slope rather than a straight line, indicating that treatment groups are most likely NOT normal. Thus, we see because our data is not normal, we do not meet the pre-requisites to carry out a two-sample t-test.

# Randomized Paired Design Noramlity checks

Now we will check the normality assumptions on the differences of our paired design
```{r echo=FALSE}
qqnorm(diff);qqline(diff)
```
(3-4)

The data mostly adheres to the normal qqline which would indicate normality, but the data deviates signifigantly from the qqline at the tails. This lack of adhesion in the tails suggests that the data may actually be following a curve with a positive slope rather than a line. Thus, the data does not seem to be normally distributed

The results of our T-test however are in agreement with our completely randomized design and our randomized paired design.

## Part IV

#Completely Randomized Design, unpaired t-test and unpaired wilcoxon test

It is unfeasible to do a full randomization test with 2 treatment groups with 20 observations each. Therefore I approximate the p-value of a randomization test with Monte Carlo Sampling, creating a vector the size of choose(40, 20) is impossible.

```{r echo=FALSE}
#completely randomized design via monte carlo
set.seed(1003836441)
pvals_crd <- replicate(1000, {treatment_s2 <- round(rexp(20, 1/3), digits = 3)
treatment_t2 <- round(rexp(20, 1), digits = 3)
bulbs2 <- c(treatment_s2, treatment_t2)
N <- 1000
res <- numeric(N)
for (i in 1:N)
  {index <- sample(40,size=20,replace=F)
    res[i] <- mean(bulbs2[index])-mean(bulbs2[-index])}
observed <- mean(treatment_s2)-mean(treatment_t2)
pval <- (sum(abs(res) >= observed)+1)/(N+1)
round(pval,2)})

round(sum(pvals_crd<=0.05)/1000, digits = 2)
```
(4-1)

We calculate the power of the Completely Randomized test to be 0.91.  

```{r echo=FALSE}
#two sided t-test 
set.seed(1003836441)
pvals_tr <- replicate(1000,(t.test(round(rexp(20, 1/3), digits = 3), round(rexp(20, 1), digits = 3), var.equal=F, alternative = "two.sided")$p.value))

round(sum(pvals_tr<=0.05)/1000, digits=2)
```
(4-2)

We calculate the power of the two-sided t-test to be 0.88

```{r echo=FALSE}
#wilcox 
set.seed(1003836441)
pvals_wil <- replicate(1000, wilcox.test(round(rexp(20,1/3), digits=3),round(rexp(20,1), digits=3), exact=F)$p.value)

round(sum(pvals_wil<=0.05)/1000, digits=2)
```
(4-3)

We calculate the power of the non-parametric Wilcoxon-Rank sum test to be 0.82

Based on the following results, for the completely randomized design I would recommend the randomized distribution test. The test has the highest power out of the three tests, that is, it is the highest probability of succesfully rejecting the null hypothesis when the alternative is true, and does not need normality assumptions to be run. Furthermore, with Monte Carlo sampling, it is as computationally feasible as the wilcox test and the t-test.

# Randomized Paired design, paired t-test and wilcoxon test

For doing 1000 repetitions of the randomized pair design, it was necessary to test only a small subset of possible randomized possible permutations, as 2^(20) is over 1,048,576 permutations, which would be repeated 1,000 times. This was unfeasible so we are limiting our permutation set to 2^(10) for quicker compute times.
```{r echo=FALSE}
#randomized paired design
set.seed(1003836441)
pvals_rpd <- replicate(1000, {diff_2 <- round(rexp(20,1/3), digits=3) - round(rexp(20,1), digits=3)
meandiff_2 <- mean(diff_2);meandiff_2
N <- 2^(10)
res <- numeric(N)
LR <- list(c(-1,1))
treatment_assignment <- expand.grid(rep(LR, 10))

for (i in 1:N)
  res[i] <- mean(as.numeric(treatment_assignment[i,])*diff_2)
pval_rpd <- sum(abs(res)>=meandiff_2)/N ; pval_rpd})

round(sum(pvals_rpd<=0.05)/1000, digits=2)
```
(4-4)

We calculate the power of the Randomized Paired Design test to be 0.83
```{r echo=FALSE}
#two sided t-test with pairing
set.seed(1003836441)
pvals_trpd <- replicate(1000,(t.test(round(rexp(20, 1/3), digits = 3), round(rexp(20, 1), digits = 3), paired=T, var.equal=F, alternative = "two.sided")$p.value))

round(sum(pvals_trpd<=0.05)/1000, digits=2)
```
(4-5)

We calculate the power of the Two Sided T-Test with pairing to be 0.86
```{r echo=FALSE}
#wilcox t.test
set.seed(1003836441)
pvals_wil <- replicate(1000, wilcox.test(round(rexp(20,1/3), digits=3),round(rexp(20,1), digits=3), paired=T, exact=F)$p.value)

round(sum(pvals_wil<=0.05)/1000, digits=2)
```
(4-6)

We calculate the power of the Paired Wilcoxon test to be 0.83

Based on the following results, each test seems to have the same power, with the two-sided t-test having slightly more power than the other two tests. However, the two-sided t-test does rely on normality, and as stated earlier, the data does not appear to be normally distributed. Therefore, the Wilcoxon-Rank test and the Randomized Pairs test are the best tests to use for this type of situation. Lastly, due to the computational intensity of the Randomized Pairs test, it is recommended to use the Wilcoxon-Rank test.

### Appendix

```{r}
library(ggplot2)
set.seed(1003836441)
treatment_s <- round(rexp(9, 1/3), digits=3)
treatment_t <- round(rexp(9, 1), digits = 3)

pairs <- data.frame(treatment_s, treatment_t)
print(pairs)
ggplot(pairs, aes(x=1:9), xlab="pair", ylab="Time") +
  geom_point(aes(y=treatment_s, color = "treatment_s")) +
  geom_point(aes(y=treatment_t, color="treatment_t")) +
  ggtitle("Treatment S paired with Treatment T") +
  xlab("Pair number") +
  ylab("Years before burning")
```
(1-1)

```{r}
round((mean(treatment_s)-mean(treatment_t)), digits=3)
```
(2-1)

```{r}
bulbs <- c(treatment_s, treatment_t)
N <- choose(18, 9)
res <- numeric(N)
index <- combn(1:18, 9)
for (i in 1:N)
{res[i] <- mean(bulbs[index[,i]])-mean(bulbs[-index[,i]])}

hist(res, xlab="difference between pair averages",
     main="Randomization Distribution of Difference in Means")
observed <- mean(treatment_s)-mean(treatment_t)
abline(v=observed, col="red")
abline(v=-observed, col="red")


pval <- round((sum(abs(res)>=observed)/N), digits = 2)
print(pval)

```
(2-2)

```{r}
diff <- pairs$treatment_s-pairs$treatment_t
meandiff <- mean(diff) ; meandiff

N <- 2^(9)
res <- numeric(N)
LR <- list(c(-1,1))
treatment_assignment <-expand.grid(rep(LR, 9))

for (i in 1:N)
  res[i] <-mean(as.numeric(treatment_assignment[i,])*diff)

hist(res, xlab="Mean Difference", main="Randomized Pairs Distribution")
abline(v=meandiff, col="red")
abline(v=-meandiff, col="red")

pval <- round(sum(abs(res)>=meandiff)/N,digits=2) ; pval
```
(2-3)

```{r}
t.test(treatment_s,treatment_t,var.equal=FALSE)
```
(3-1)

```{r}
t.test(pairs$treatment_s,pairs$treatment_t,paired=T)
```
(3-2)

```{r}
qqnorm(treatment_s, main="Treatment S");qqline(treatment_s)
qqnorm(treatment_t,main="Treatment T");qqline(treatment_t)

```
(3-3)

```{r}
qqnorm(diff);qqline(diff)
```
(3-4)

```{r}
#completely randomized design via monte carlo
set.seed(1003836441)
pvals_crd <- replicate(1000, {treatment_s2 <- round(rexp(20, 1/3), digits = 3)
treatment_t2 <- round(rexp(20, 1), digits = 3)
bulbs2 <- c(treatment_s2, treatment_t2)
N <- 1000
res <- numeric(N)
for (i in 1:N)
  {index <- sample(40,size=20,replace=F)
    res[i] <- mean(bulbs2[index])-mean(bulbs2[-index])}
observed <- mean(treatment_s2)-mean(treatment_t2)
pval <- (sum(abs(res) >= observed)+1)/(N+1)
round(pval,2)})

round(sum(pvals_crd<=0.05)/1000, digits = 2)
```
(4-1)

```{r}
#two sided t-test 
set.seed(1003836441)
pvals_tr <- replicate(1000,(t.test(round(rexp(20, 1/3), digits = 3), round(rexp(20, 1), digits = 3), var.equal=F, alternative = "two.sided")$p.value))

round(sum(pvals_tr<=0.05)/1000, digits=2)
```
(4-2)

```{r}
#wilcox 
set.seed(1003836441)
pvals_wil <- replicate(1000, wilcox.test(round(rexp(20,1/3), digits=3),round(rexp(20,1), digits=3), exact=F)$p.value)

round(sum(pvals_wil<=0.05)/1000, digits=2)
```
(4-3)

```{r}
#randomized paired design
set.seed(1003836441)
pvals_rpd <- replicate(1000, {diff_2 <- round(rexp(20,1/3), digits=3) - round(rexp(20,1), digits=3)
meandiff_2 <- mean(diff_2);meandiff_2
N <- 2^(10)
res <- numeric(N)
LR <- list(c(-1,1))
treatment_assignment <- expand.grid(rep(LR, 10))

for (i in 1:N)
  res[i] <- mean(as.numeric(treatment_assignment[i,])*diff_2)
pval_rpd <- sum(abs(res)>=meandiff_2)/N ; pval_rpd})

round(sum(pvals_rpd<=0.05)/1000, digits=2)
```
(4-4)

```{r}
#two sided t-test with pairing
set.seed(1003836441)
pvals_trpd <- replicate(1000,(t.test(round(rexp(20, 1/3), digits = 3), round(rexp(20, 1), digits = 3), paired=T, var.equal=F, alternative = "two.sided")$p.value))

round(sum(pvals_trpd<=0.05)/1000, digits=2)
```
(4-5)

```{r}
#wilcox t.test
set.seed(1003836441)
pvals_wil <- replicate(1000, wilcox.test(round(rexp(20,1/3), digits=3),round(rexp(20,1), digits=3), paired=T, exact=F)$p.value)

round(sum(pvals_wil<=0.05)/1000, digits=2)
```
(4-6)
